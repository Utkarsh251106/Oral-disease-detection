{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06d378-f6b4-499f-8ead-a3126a279126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d7aa4-f5d5-4acd-9a52-09588a6040e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResultsSaver:\n",
    "    def __init__(self, model_name='oral_disease_model'):\n",
    "        self.model_name = model_name\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.results_dir = f'model_results_{self.timestamp}'\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "        \n",
    "    def save_metrics(self, y_true, y_pred, class_names):\n",
    "        \"\"\"\n",
    "        Calculate and save all metrics\n",
    "        \"\"\"\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': float(np.mean(y_true == y_pred)),\n",
    "            'f1_macro': float(f1_score(y_true, y_pred, average='macro')),\n",
    "            'f1_weighted': float(f1_score(y_true, y_pred, average='weighted')),\n",
    "            'precision_macro': float(precision_score(y_true, y_pred, average='macro')),\n",
    "            'precision_weighted': float(precision_score(y_true, y_pred, average='weighted')),\n",
    "            'recall_macro': float(recall_score(y_true, y_pred, average='macro')),\n",
    "            'recall_weighted': float(recall_score(y_true, y_pred, average='weighted'))\n",
    "        }\n",
    "        \n",
    "        # Get per-class metrics\n",
    "        report_dict = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "        \n",
    "        # Save metrics as JSON\n",
    "        with open(f'{self.results_dir}/metrics.json', 'w') as f:\n",
    "            json.dump({\n",
    "                'overall_metrics': metrics,\n",
    "                'per_class_metrics': report_dict\n",
    "            }, f, indent=4)\n",
    "        \n",
    "        # Save metrics as CSV for easy viewing\n",
    "        df_metrics = pd.DataFrame(report_dict).transpose()\n",
    "        df_metrics.to_csv(f'{self.results_dir}/metrics.csv')\n",
    "        \n",
    "        return metrics, report_dict\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, class_names):\n",
    "        \"\"\"\n",
    "        Plot and save confusion matrix\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names\n",
    "        )\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.results_dir}/confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Save confusion matrix as CSV\n",
    "        df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "        df_cm.to_csv(f'{self.results_dir}/confusion_matrix.csv')\n",
    "\n",
    "    def save_training_history(self, history):\n",
    "        \"\"\"\n",
    "        Save training history plots and metrics\n",
    "        \"\"\"\n",
    "        # Save history as JSON\n",
    "        with open(f'{self.results_dir}/training_history.json', 'w') as f:\n",
    "            history_dict = {key: [float(val) for val in values] \n",
    "                          for key, values in history.history.items()}\n",
    "            json.dump(history_dict, f, indent=4)\n",
    "        \n",
    "        # Plot training history\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax1.plot(history.history['accuracy'], label='Training')\n",
    "        ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "        ax1.set_title('Model Accuracy')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Accuracy')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Loss plot\n",
    "        ax2.plot(history.history['loss'], label='Training')\n",
    "        ax2.plot(history.history['val_loss'], label='Validation')\n",
    "        ax2.set_title('Model Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.results_dir}/training_history.png')\n",
    "        plt.close()\n",
    "\n",
    "    def generate_report(self, metrics, class_names, model_params=None):\n",
    "        \"\"\"\n",
    "        Generate a comprehensive HTML report\n",
    "        \"\"\"\n",
    "        html_content = f\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Model Evaluation Report</title>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "                table {{ border-collapse: collapse; width: 100%; }}\n",
    "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "                th {{ background-color: #f2f2f2; }}\n",
    "                .metric-value {{ font-weight: bold; color: #2c3e50; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Model Evaluation Report - {self.model_name}</h1>\n",
    "            <p>Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\n",
    "            \n",
    "            <h2>Overall Metrics</h2>\n",
    "            <table>\n",
    "                <tr><th>Metric</th><th>Value</th></tr>\n",
    "                <tr><td>Accuracy</td><td class=\"metric-value\">{metrics['accuracy']:.4f}</td></tr>\n",
    "                <tr><td>F1 Score (Macro)</td><td class=\"metric-value\">{metrics['f1_macro']:.4f}</td></tr>\n",
    "                <tr><td>F1 Score (Weighted)</td><td class=\"metric-value\">{metrics['f1_weighted']:.4f}</td></tr>\n",
    "                <tr><td>Precision (Macro)</td><td class=\"metric-value\">{metrics['precision_macro']:.4f}</td></tr>\n",
    "                <tr><td>Recall (Macro)</td><td class=\"metric-value\">{metrics['recall_macro']:.4f}</td></tr>\n",
    "            </table>\n",
    "            \n",
    "            <h2>Visualizations</h2>\n",
    "            <p>The following visualizations have been saved:</p>\n",
    "            <ul>\n",
    "                <li>Confusion Matrix: confusion_matrix.png</li>\n",
    "                <li>Training History: training_history.png</li>\n",
    "            </ul>\n",
    "            \n",
    "            <h2>Class Names</h2>\n",
    "            <ul>\n",
    "                {' '.join(f'<li>{name}</li>' for name in class_names)}\n",
    "            </ul>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(f'{self.results_dir}/report.html', 'w') as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "# Example usage\n",
    "def save_all_results(model, history, test_ds, class_names):\n",
    "    \"\"\"\n",
    "    Save all results after model training\n",
    "    \"\"\"\n",
    "    # Initialize results saver\n",
    "    results_saver = ModelResultsSaver()\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for images, labels in test_ds:\n",
    "        pred = model.predict(images)\n",
    "        pred_classes = np.argmax(pred, axis=1)\n",
    "        y_pred.extend(pred_classes)\n",
    "        y_true.extend(labels.numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    # Save all results\n",
    "    metrics, _ = results_saver.save_metrics(y_true, y_pred, class_names)\n",
    "    results_saver.plot_confusion_matrix(y_true, y_pred, class_names)\n",
    "    results_saver.save_training_history(history)\n",
    "    results_saver.generate_report(metrics, class_names)\n",
    "    \n",
    "    print(f\"All results saved in directory: {results_saver.results_dir}\")\n",
    "\n",
    "# Use in your main training script:\n",
    "\"\"\"\n",
    "# After training:\n",
    "save_all_results(model, history, test_ds, class_names)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83b34c-1a4b-455b-b742-7124d47965d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3b732b-1cd7-437e-86ed-d85d9ffd396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b028bcf7-23e2-4968-9505-640d4ec871d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_SIZE = (320, 320)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c781d513-0494-4593-aa18-461c3610cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to preprocess images using OpenCV\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    image = cv2.resize(image, IMG_SIZE)  # Resize to 320x320\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba92b02b-daf1-491d-8a2d-c0b31e13e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data loader using OpenCV\n",
    "def load_dataset(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(directory))  # Ensure consistent ordering\n",
    "    class_map = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "    for cls in class_names:\n",
    "        class_dir = os.path.join(directory, cls)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            images.append(preprocess_image(img_path))\n",
    "            labels.append(class_map[cls])\n",
    "    return np.array(images), np.array(labels), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e67a5-c2b9-4d7f-8c1e-76a56f70ace8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c4cdaf-2771-454f-b51f-c79f42c05a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.5094 - loss: 0.7000 - val_accuracy: 0.5111 - val_loss: 0.6994\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.5236 - loss: 0.6942 - val_accuracy: 0.5111 - val_loss: 0.6935\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.5518 - loss: 0.6896 - val_accuracy: 0.5111 - val_loss: 0.6929\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.5382 - loss: 0.6907 - val_accuracy: 0.5111 - val_loss: 0.6930\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.5193 - loss: 0.6924 - val_accuracy: 0.5111 - val_loss: 0.6952\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.5441 - loss: 0.6899 - val_accuracy: 0.5111 - val_loss: 0.6936\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.5321 - loss: 0.6918 - val_accuracy: 0.5111 - val_loss: 0.6944\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.5292 - loss: 0.6919 - val_accuracy: 0.5111 - val_loss: 0.6948\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1s/step - accuracy: 0.5333 - loss: 0.6918 - val_accuracy: 0.5111 - val_loss: 0.6938\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.5473 - loss: 0.6895 - val_accuracy: 0.5111 - val_loss: 0.6939\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7389 - loss: 0.6637\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step\n",
      "Confusion Matrix:\n",
      "[[76  0]\n",
      " [69  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Caries       0.52      1.00      0.69        76\n",
      "  Gingivitis       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.52       145\n",
      "   macro avg       0.26      0.50      0.34       145\n",
      "weighted avg       0.27      0.52      0.36       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_images, train_labels, class_names = load_dataset(\"dataset/train\")\n",
    "valid_images, valid_labels, _ = load_dataset(\"dataset/valid\")\n",
    "test_images, test_labels, _ = load_dataset(\"dataset/test\")\n",
    "\n",
    "# One-hot encode labels\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=len(class_names))\n",
    "valid_labels = tf.keras.utils.to_categorical(valid_labels, num_classes=len(class_names))\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(class_names))\n",
    "\n",
    "# EfficientNetB0 model\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(320, 320, 3))\n",
    "base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "# Custom classification head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=train_images, y=train_labels,\n",
    "    validation_data=(valid_images, valid_labels),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"oral_disease_model.keras\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)\n",
    "y_true = np.argmax(test_labels, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Metrics\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Save metrics to a file\n",
    "results = {\n",
    "    \"accuracy\": test_acc,\n",
    "    \"classification_report\": report,\n",
    "    \"confusion_matrix\": conf_matrix.tolist()\n",
    "}\n",
    "\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c1b91-b729-4003-925f-d1f9c6e8c4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4aabaa-595b-47e0-8a79-f2c62210c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5590a-136f-40ea-844d-119b80e3442c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3177 files belonging to 2 classes.\n",
      "Found 135 files belonging to 2 classes.\n",
      "Found 145 files belonging to 2 classes.\n",
      "Class Weights: {0: 0.9289473684210526, 1: 1.0828220858895705}\n",
      "Epoch 1/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m787s\u001b[0m 8s/step - accuracy: 0.9115 - loss: 0.2122 - val_accuracy: 0.8889 - val_loss: 1.1951\n",
      "Epoch 2/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 7s/step - accuracy: 0.9866 - loss: 0.0451 - val_accuracy: 0.9704 - val_loss: 0.1708\n",
      "Epoch 3/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 7s/step - accuracy: 0.9835 - loss: 0.0476 - val_accuracy: 0.9778 - val_loss: 0.1691\n",
      "Epoch 4/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 7s/step - accuracy: 0.9903 - loss: 0.0293 - val_accuracy: 0.8000 - val_loss: 1.6271\n",
      "Epoch 5/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 7s/step - accuracy: 0.9863 - loss: 0.0393 - val_accuracy: 0.8519 - val_loss: 0.5870\n",
      "Epoch 6/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 7s/step - accuracy: 0.9855 - loss: 0.0399 - val_accuracy: 0.9630 - val_loss: 0.1412\n",
      "Epoch 7/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m781s\u001b[0m 8s/step - accuracy: 0.9906 - loss: 0.0320 - val_accuracy: 0.9778 - val_loss: 0.1417\n",
      "Epoch 8/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 8s/step - accuracy: 0.9952 - loss: 0.0117 - val_accuracy: 0.9926 - val_loss: 0.0596\n",
      "Epoch 9/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 8s/step - accuracy: 0.9976 - loss: 0.0087 - val_accuracy: 0.9852 - val_loss: 0.2737\n",
      "Epoch 10/30\n",
      "\u001b[1m 81/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:25\u001b[0m 8s/step - accuracy: 0.9930 - loss: 0.0189"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "img_size = (320, 320)\n",
    "\n",
    "# Function to create a dataset from directories\n",
    "def create_dataset(directory):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = create_dataset(\"dataset/train\")\n",
    "valid_dataset = create_dataset(\"dataset/valid\")\n",
    "test_dataset = create_dataset(\"dataset/test\")\n",
    "\n",
    "# Determine class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch datasets for performance\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "train_labels = np.concatenate([y.numpy() for _, y in train_dataset], axis=0)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(train_labels), y=train_labels\n",
    ")\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Class Weights:\", class_weights_dict)\n",
    "\n",
    "# Build the model\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(320, 320, 3))\n",
    "base_model.trainable = True\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3, decay_steps=1000, decay_rate=0.9\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=30,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Generate predictions and calculate metrics\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
    "y_pred = np.argmax(model.predict(test_dataset), axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    \"accuracy\": test_acc,\n",
    "    \"classification_report\": report,\n",
    "    \"confusion_matrix\": conf_matrix.tolist()\n",
    "}\n",
    "\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"oral_disease_model.h5\")\n",
    "\n",
    "print(\"Results and model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4c34f-e802-48cf-a6df-131c157f2b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
